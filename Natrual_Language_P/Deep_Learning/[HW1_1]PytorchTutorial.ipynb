{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR26RFkwXtvi"
      },
      "source": [
        "# **[HW1.1] PyTorch Tutorial**\n",
        "1. Install packages\n",
        "2. Tensor\n",
        "3. AutoGrad\n",
        "\n",
        "딥러닝 실습은, 수업시간에 배웠던 개념들을 직접 코드로 옮겨보며 이를 폭넓게 이해하는 데에 초점을 맞추고 있습니다. 실습에서 사용한 예시 외에도, 다양한 architecture를 직접 구성해보며 각 node와 function의 역할을 명확히 이해해보시길 바랍니다.\n",
        "\n",
        "이번 실습에서는 딥러닝 모델을 만들때 사용하는 PyTorch library에 대한 기본 개념들을 익혀보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4iquuOQj1g9"
      },
      "source": [
        "# 1. Import packages\n",
        "\n",
        "> 필요한 package를 설치하고 import합니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpvlE_XOWS33"
      },
      "source": [
        "런타임의 유형을 변경해줍니다.\n",
        "\n",
        "상단 메뉴에서 [런타임]->[런타임유형변경]->[하드웨어가속기]->[GPU]\n",
        "\n",
        "변경 이후 아래의 cell을 실행 시켰을 때, torch.cuda.is_avialable()이 True가 나와야 합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqVdEuPQzMAH",
        "outputId": "65821358-847d-4d58-e349-ee19914e3ae4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.1+cu113\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o3-HPdHLZma"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "\n",
        "np.set_printoptions(precision=3)\n",
        "np.set_printoptions(suppress=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMkIJgfEl9kD"
      },
      "source": [
        "# 2. Tensor operations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxQqLw-Dl_Zw"
      },
      "source": [
        "텐서(tensor)는 배열(array)이나 행렬(matrix)과 매우 유사한 특수한 자료구조입니다. PyTorch에서는 텐서를 사용하여 모델의 입력과 출력뿐만 아니라 모델의 파라미터를 나타냅니다.\n",
        "\n",
        "GPU나 다른 연산 가속을 위한 특수한 하드웨어에서 실행할 수 있다는 점을 제외하면, 텐서는 NumPy의 ndarray와 매우 유사합니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8XqtZa8sXsw"
      },
      "source": [
        "##텐서 초기화하기\n",
        "\n",
        "데이터로부터 직접 생성하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCnmrA9ltYs0",
        "outputId": "0059b673-cddb-45d4-f926-3e4ebfa4a503",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data = [[1, 2],[3, 4]]\n",
        "x = torch.tensor(data)\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZx51U6fUXSc"
      },
      "source": [
        "Numpy array로부터 생성하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5m4qus2UnoL",
        "outputId": "5e6eed07-6ad8-476b-b2a1-41aa6a04b967",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np_array = np.array(data)\n",
        "x = torch.from_numpy(np_array)\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BfwipaTYEFI"
      },
      "source": [
        "Tensor에서 Numpy array로 변환하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upkEJ9mBMCOd",
        "outputId": "17d85176-c609-4d44-9efc-edf5b43edde8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x.numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2],\n",
              "       [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obZ-A5rxYOSx"
      },
      "source": [
        "다른 텐서와 같은 모양의 텐서 초기화하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkJRGOaEyyc0",
        "outputId": "46f56f54-d121-4b1b-b9c5-d4f2522f7f5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_ones = torch.ones_like(x) # x_data의 속성을 유지합니다.\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(x, dtype=torch.float) # x_data의 속성을 덮어씁니다.\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.5606, 0.4931],\n",
            "        [0.2193, 0.1942]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1E5bEPHZskg"
      },
      "source": [
        "주어진 shape으로 초기화하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pk1OASeazKtN",
        "outputId": "14f38daf-ddea-431e-f5f5-4fbdcb745258",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "shape = (3,4)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.5824, 0.2464, 0.1527, 0.1181],\n",
            "        [0.1386, 0.8924, 0.2786, 0.6315],\n",
            "        [0.9681, 0.2847, 0.0347, 0.1919]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB-u3e9taDjT"
      },
      "source": [
        "## 텐서의 속성\n",
        "\n",
        "텐서의 속성은 텐서의 모양(shape), 자료형(datatype) 및 어느 장치에 저장되는지를 나타냅니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HWWRcNjaLDi",
        "outputId": "2f8c0232-24df-4bbf-c22e-293b8beeaef5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tensor = torch.rand(3,4)\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A7LymV5aYEA"
      },
      "source": [
        "아래와 같이 cpu에 할당되어 있는 tensor를 gpu에 옮길 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKvYqt3ZaOXZ",
        "outputId": "cc51f3bc-7f3f-4c95-9867-cda6e89ec800",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "device = torch.device('cuda')\n",
        "tensor = tensor.to(device)\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device tensor is stored on: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01vssH7n24cq"
      },
      "source": [
        "## 텐서 연산"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqON2YtYczmS"
      },
      "source": [
        "Numpy식의 인덱싱과 슬라이싱"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOv_w4LhjTDq",
        "outputId": "306417bc-562b-413a-93f5-3777062132e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tensor = torch.ones(3, 4)\n",
        "tensor[:,1] = 0\n",
        "print(tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR0J9p1WkpHO"
      },
      "source": [
        "텐서 합치기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s68HmhqlknkX",
        "outputId": "e1e0c941-4c4f-4932-e5d4-db918309d8d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=0)\n",
        "print(t1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYxrFYAjbQuS",
        "outputId": "8cbc2c2d-b282-44c8-a184-d78ac226f481",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThLzN1ONbV-p"
      },
      "source": [
        "텐서 곱하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCMMXj8ejXVG",
        "outputId": "7b3bf283-4f35-4ac2-ce16-4ea69628c92b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 요소별 곱(element-wise product)을 계산합니다\n",
        "print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n",
        "\n",
        "# 다른 문법:\n",
        "print(f\"tensor * tensor \\n {tensor * tensor}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor.mul(tensor) \n",
            " tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]]) \n",
            "\n",
            "tensor * tensor \n",
            " tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9752P1u90enu"
      },
      "source": [
        "텐서간 matrix multiplication 진행하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhOPv757T4NG",
        "outputId": "9ea15842-88f1-4f04-9df5-7348bed72305",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n",
        "# 다른 문법:\n",
        "print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor.matmul(tensor.T) \n",
            " tensor([[3., 3., 3.],\n",
            "        [3., 3., 3.],\n",
            "        [3., 3., 3.]]) \n",
            "\n",
            "tensor @ tensor.T \n",
            " tensor([[3., 3., 3.],\n",
            "        [3., 3., 3.],\n",
            "        [3., 3., 3.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sC_i0POOIf0M"
      },
      "source": [
        "# 3. AUTOGRAD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tQLTW4vcRJK"
      },
      "source": [
        "PyTorch에는 torch.autograd라고 불리는 자동 미분 엔진이 내장되어 있습니다. \n",
        "이는 모든 node에 대한 미분 값을 자동으로 계산해주게 됩니다.\n",
        "\n",
        "입력 X, 파라미터 W , 그리고 cross-entropy loss를 사용하는 logistic regression model의 gradient를 autograd를 이용해서 구해보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-b3w8_NGdCL1"
      },
      "source": [
        "## 입력 및 파라미터 초기화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52zAKX7zLl7n",
        "outputId": "3f91c981-7332-4238-fae8-102511931dcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = torch.ones(5)  # input tensor\n",
        "y = torch.zeros(3)  # expected output\n",
        "w = torch.randn(5, 3, requires_grad=True)\n",
        "b = torch.randn(3, requires_grad=True)\n",
        "print(x)\n",
        "print(y)\n",
        "print(w)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "tensor([0., 0., 0.])\n",
            "tensor([[ 0.2490,  1.7429, -2.1038],\n",
            "        [ 0.0108,  0.0890,  0.6241],\n",
            "        [-0.6494,  0.8989, -1.0319],\n",
            "        [-0.2609,  0.1454, -1.6543],\n",
            "        [-1.2576, -0.5483,  0.0698]], requires_grad=True)\n",
            "tensor([-0.0060,  0.2702, -0.4797], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfSzTTVUeb06"
      },
      "source": [
        "## Forward"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09v6hrSIecG-",
        "outputId": "a4fcd9ce-95bf-4a94-c869-61e80ae37156",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "z = torch.matmul(x,w)+b\n",
        "z"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.9142,  2.5980, -4.5758], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1R19jHY9Pemt"
      },
      "source": [
        "## Loss Function\n",
        "\n",
        "PyTorch에서는 node를 크게 2가지의 방법의 api를 활용해서 사용합니다.\n",
        "\n",
        "1. [torch.nn](https://pytorch.org/docs/stable/nn.html)\n",
        "2. [torch.nn.functional](https://pytorch.org/docs/stable/nn.functional.html)\n",
        "\n",
        "torch.nn은 사전에 node를 초기화 시켜놓고, 해당 node에 텐서를 통과시켜 값을 받는 형태인 반면, torch.nn.functional은 사전에 초기화없이 바로 함수처럼 사용하는 방식입니다.\n",
        "\n",
        "코딩 스타일에 맞춰 원하시는 api를 선택하셔서 사용하시면 됩니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TQe1Nw8QLMu",
        "outputId": "ab59eddd-8bbe-45e1-e817-f716ded9f6ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "loss = loss_fn(z, y)\n",
        "loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9392, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gihsaH3ULCRN",
        "outputId": "856fb31f-f3fc-4f9c-b853-50e1c03123a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)\n",
        "loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9392, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCsd5yep3-sj"
      },
      "source": [
        "## Backward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfNejCDye61c"
      },
      "source": [
        "모델에서 매개변수의 가중치를 최적화하려면 파라미터에 대한 loss function의 도함수(derivative)를 계산해야 합니다. \n",
        "이러한 도함수를 계산하기 위해, loss.backward() 를 호출한 다음 w.grad와 b.grad에서 값을 가져옵니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OptZdnLSu5vC",
        "outputId": "46d6cdf4-9f87-4c1b-bf4e-a57ce65c7428",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "loss.backward()\n",
        "print(x.grad)\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "tensor([[0.0428, 0.3102, 0.0034],\n",
            "        [0.0428, 0.3102, 0.0034],\n",
            "        [0.0428, 0.3102, 0.0034],\n",
            "        [0.0428, 0.3102, 0.0034],\n",
            "        [0.0428, 0.3102, 0.0034]])\n",
            "tensor([0.0428, 0.3102, 0.0034])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFE4lc-lfYtf"
      },
      "source": [
        "기본적으로, requires_grad=True인 모든 텐서들은 연산 기록을 추적하고 미분 계산을 지원합니다. 그러나 모델을 학습한 뒤 입력 데이터를 단순히 적용하기만 하는 경우와 같이 forward 연산만 필요한 경우에는, 미분 연산을 위한 값들을 저장해두는 것이 속력 및 메모리의 저하를 가져올 수 있습니다. 연산 코드를 torch.no_grad() 블록으로 둘러싸서 미분 추적을 멈출 수 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaiqxruWT_so",
        "outputId": "8670a01e-77a2-441f-a41f-9362619fd157",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "z = torch.matmul(x, w)+b\n",
        "print(z.requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "    z = torch.matmul(x, w)+b\n",
        "print(z.requires_grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_NqQRDaKqU6"
      },
      "source": [
        "# Reference\n",
        "\n",
        "1. https://tutorials.pytorch.kr/index.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6uX96q05Ddha"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}