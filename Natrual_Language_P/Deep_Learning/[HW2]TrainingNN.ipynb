{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "2D2tIM62sUW4",
        "xlkMXZfKxpRg",
        "b1nhBnqWxw4a"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR26RFkwXtvi"
      },
      "source": [
        "# **[HW2] Training Neural Network**\n",
        "1. Prerequisite\n",
        "2. Activation\n",
        "3. Optimizer\n",
        "4. Regularization\n",
        "5. FC vs Conv\n",
        "6. Do it by yourself\n",
        "\n",
        "이번 실습에서는 지난 시간에 배웠던 MLP-layer의 component들을 하나씩 바꿔가며 activation, optimizer, regularization, convolution layer등의 중요성을 하나씩 익혀가는 시간을 갖도록 하겠습니다.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xp3f6JjmmlC3"
      },
      "source": [
        "# 1. Prerequisite\n",
        "\n",
        "본격적인 실습을 진행하기 이전, 지난 [HW1.2 Logistic Regression vs MLP]에서 진행했던것과 동일하게 \\\\\n",
        "Mnist dataset에 대해서 DataLoader와 Trainer class를 생성해두겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crVJ36mMlaXP"
      },
      "source": [
        "\n",
        "\n",
        "## Import packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpvlE_XOWS33"
      },
      "source": [
        "런타임의 유형을 변경해줍니다.\n",
        "\n",
        "상단 메뉴에서 [런타임]->[런타임유형변경]->[하드웨어가속기]->[GPU]\n",
        "\n",
        "변경 이후 아래의 cell을 실행 시켰을 때, torch.cuda.is_avialable()이 True가 나와야 합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqVdEuPQzMAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec81b917-c048-4b5f-d268-406ebb6bd5f3"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "from torch.utils import data\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.1+cu113\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o3-HPdHLZma"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "np.set_printoptions(precision=3)\n",
        "np.set_printoptions(suppress=True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMkIJgfEl9kD"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCnmrA9ltYs0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1acb36a7-b327-433a-abf8-d6c3b6d30d9f"
      },
      "source": [
        "mnist = fetch_openml('mnist_784', cache=False)\n",
        "X = mnist.data.astype('float32').values\n",
        "y = mnist.target.astype('int64').values\n",
        "X /= 255.0\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(70000, 784)\n",
            "(70000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB-u3e9taDjT"
      },
      "source": [
        "## Split Dataset\n",
        "\n",
        "학습과 평가를 위한 dataset으로 나눕니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HWWRcNjaLDi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8efc185d-ee7c-4b78-da9f-457fdc3aa32f"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(56000, 784)\n",
            "(56000,)\n",
            "(14000, 784)\n",
            "(14000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYnvqbdijWUQ"
      },
      "source": [
        "## Pytorch Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ypqp7zA-xRlB"
      },
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        super(CustomDataset, self).__init__()\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.X[index]\n",
        "        y = self.y[index]\n",
        "        x = torch.from_numpy(x).float()\n",
        "        y = torch.from_numpy(np.array(y)).long()\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTr4OWatzmaU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3395892b-e134-47c4-a96b-4650501d7063"
      },
      "source": [
        "train_dataset = CustomDataset(X_train, y_train)\n",
        "test_dataset = CustomDataset(X_test, y_test)\n",
        "\n",
        "print(len(train_dataset))\n",
        "print(train_dataset.X.shape)\n",
        "print(len(test_dataset))\n",
        "print(test_dataset.X.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "56000\n",
            "(56000, 784)\n",
            "14000\n",
            "(14000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51PT-uPVzE8_"
      },
      "source": [
        "## DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2k3YVBoxRnF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "191ba33d-6c85-4b85-d428-473cff898240"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "# shuffle the train data\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# do not shuffle the val & test data\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# dataset size // batch_size\n",
        "print(len(train_dataloader))\n",
        "print(len(test_dataloader))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "875\n",
            "219\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BN65oTBk1d4T"
      },
      "source": [
        "## Trainer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJqIwSltn9uY"
      },
      "source": [
        "class Trainer():\n",
        "    def __init__(self, trainloader, testloader, model, optimizer, criterion, device):\n",
        "        \"\"\"\n",
        "        trainloader: train data's loader\n",
        "        testloader: test data's loader\n",
        "        model: model to train\n",
        "        optimizer: optimizer to update your model\n",
        "        criterion: loss function\n",
        "        \"\"\"\n",
        "        self.trainloader = trainloader\n",
        "        self.testloader = testloader\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion = criterion\n",
        "        self.device = device\n",
        "        \n",
        "    def train(self, epoch = 1):\n",
        "        self.model.train()\n",
        "        for e in range(epoch):\n",
        "            running_loss = 0.0  \n",
        "            for i, data in enumerate(self.trainloader, 0): \n",
        "                inputs, labels = data \n",
        "                # model에 input으로 tensor를 gpu-device로 보낸다\n",
        "                inputs = inputs.to(self.device)  \n",
        "                labels = labels.to(self.device)\n",
        "                # zero the parameter gradients\n",
        "                self.optimizer.zero_grad()    \n",
        "                # forward + backward + optimize\n",
        "                outputs = self.model(inputs) \n",
        "                loss = self.criterion(outputs, labels)  \n",
        "                loss.backward() \n",
        "                self.optimizer.step() \n",
        "                running_loss += loss.item()\n",
        "            \n",
        "            print('epoch: %d  loss: %.3f' % (e + 1, running_loss / len(self.trainloader)))\n",
        "            running_loss = 0.0\n",
        "        \n",
        "    def test(self):\n",
        "        self.model.eval() \n",
        "        correct = 0\n",
        "        for inputs, labels in self.testloader:\n",
        "            inputs = inputs.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "            output = self.model(inputs) \n",
        "            pred = output.max(1, keepdim=True)[1] # get the index of the max \n",
        "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        test_acc = correct / len(self.testloader.dataset)\n",
        "        print('test_acc: %.3f' %(test_acc))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1GnKJCB4T_Q"
      },
      "source": [
        "# 2. Activation Function\n",
        "\n",
        "이번 section에서는 가장 대표적으로 사용되는 sigmoid function과 relu function을 사용해보고 비교해보도록 하겠습니다.\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1xfJBd9v9L_RgXGf8urNrYpb40zXU6gea)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUhK8GHx0704"
      },
      "source": [
        "- input: 784\n",
        "- hidden: 32 or (32, 32)\n",
        "- output: 10\n",
        "- **activation: sigmoid or relu**\n",
        "- optimizer: sgd\n",
        "- loss: cross-entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zPmZhpZlZkQ"
      },
      "source": [
        "## 2-layer Network + Sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPfV0OTc4Xdr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae452651-b277-495a-e63c-73cd8faaf9ef"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim=784, \n",
        "                 hidden_dim=32, \n",
        "                 output_dim=10):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.sigmoid(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = MLP()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "device = torch.device('cuda')\n",
        "model.to(device)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (fc1): Linear(in_features=784, out_features=32, bias=True)\n",
              "  (fc2): Linear(in_features=32, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKqcfL4_qK6Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06465e13-7cfd-4934-d020-915d1966b1aa"
      },
      "source": [
        "trainer = Trainer(trainloader = train_dataloader,\n",
        "                  testloader = test_dataloader,\n",
        "                  model = model,\n",
        "                  criterion = criterion,\n",
        "                  optimizer = optimizer,\n",
        "                  device = device)\n",
        "\n",
        "trainer.train(epoch = 10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1  loss: 2.193\n",
            "epoch: 2  loss: 1.820\n",
            "epoch: 3  loss: 1.384\n",
            "epoch: 4  loss: 1.084\n",
            "epoch: 5  loss: 0.895\n",
            "epoch: 6  loss: 0.769\n",
            "epoch: 7  loss: 0.679\n",
            "epoch: 8  loss: 0.613\n",
            "epoch: 9  loss: 0.563\n",
            "epoch: 10  loss: 0.524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgD1bTOzqK-n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2801f0c6-6f06-44ec-908c-f0ae039492f1"
      },
      "source": [
        "trainer.test()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_acc: 0.878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKxP2nzvVC_O"
      },
      "source": [
        "## 2-layer Network + ReLU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gRfskIWWQEf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca9bf67b-a9f7-4e65-8148-a83e46021962"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim=784, \n",
        "                 hidden_dim=32, \n",
        "                 output_dim=10):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = MLP()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "device = torch.device('cuda')\n",
        "model.to(device)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (fc1): Linear(in_features=784, out_features=32, bias=True)\n",
              "  (fc2): Linear(in_features=32, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVKoXvlYryMK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bca3653-ba19-46b2-eee1-4a381e7c2f4b"
      },
      "source": [
        "trainer = Trainer(trainloader = train_dataloader,\n",
        "                  testloader = test_dataloader,\n",
        "                  model = model,\n",
        "                  criterion = criterion,\n",
        "                  optimizer = optimizer,\n",
        "                  device = device)\n",
        "\n",
        "trainer.train(epoch = 10)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1  loss: 1.278\n",
            "epoch: 2  loss: 0.519\n",
            "epoch: 3  loss: 0.405\n",
            "epoch: 4  loss: 0.360\n",
            "epoch: 5  loss: 0.335\n",
            "epoch: 6  loss: 0.318\n",
            "epoch: 7  loss: 0.304\n",
            "epoch: 8  loss: 0.292\n",
            "epoch: 9  loss: 0.282\n",
            "epoch: 10  loss: 0.272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0wcOPU_ryOg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2617120-e4c9-4f2b-b77c-927a498de1a1"
      },
      "source": [
        "trainer.test()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_acc: 0.923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RyAkEQEr-OV"
      },
      "source": [
        "#### Q1. Activation Function에 따라 성능의 차이가 있나요? 있다면, 왜 차이가 발생했을까요?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "렐루함수는 양수일때 그값을 함수값으로 가지고 음수일때 0을 가진다. 시그모이드의 경우 원점에서 멀때 기울기가 현저히 떨어진다. 시그모이드는 학습할때 gradient가 희미해지는 특징이 있다. 이는 밑에 레이어가 더 깊어질 수록 심해져서 퍼포먼스가 렐루함수보다 차이가 심해질 것이다."
      ],
      "metadata": {
        "id": "V_dYELF_eb_j"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D2tIM62sUW4"
      },
      "source": [
        "## 3-layer Network + Sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29TauDy4ryQ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dba1ab7-f09a-4033-8c7b-80893eae3ceb"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim=784, \n",
        "                 hidden_dim=(32,32), \n",
        "                 output_dim=10):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim[0])\n",
        "        self.fc2 = nn.Linear(hidden_dim[0], hidden_dim[1])\n",
        "        self.fc3 = nn.Linear(hidden_dim[1], output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.sigmoid(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.sigmoid(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = MLP()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "device = torch.device('cuda')\n",
        "model.to(device)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (fc1): Linear(in_features=784, out_features=32, bias=True)\n",
              "  (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
              "  (fc3): Linear(in_features=32, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oS8LPa6ryVd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7edf363-94c1-403d-b148-df6cd81cb3ca"
      },
      "source": [
        "trainer = Trainer(trainloader = train_dataloader,\n",
        "                  testloader = test_dataloader,\n",
        "                  model = model,\n",
        "                  criterion = criterion,\n",
        "                  optimizer = optimizer,\n",
        "                  device = device)\n",
        "\n",
        "trainer.train(epoch = 10)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1  loss: 2.301\n",
            "epoch: 2  loss: 2.296\n",
            "epoch: 3  loss: 2.290\n",
            "epoch: 4  loss: 2.282\n",
            "epoch: 5  loss: 2.269\n",
            "epoch: 6  loss: 2.243\n",
            "epoch: 7  loss: 2.194\n",
            "epoch: 8  loss: 2.099\n",
            "epoch: 9  loss: 1.946\n",
            "epoch: 10  loss: 1.760\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfCOr5-lryZy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6611dd3-f7f3-4ffe-bc78-24f8c85c573d"
      },
      "source": [
        "trainer.test()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_acc: 0.469\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zPtZFsZtAVy"
      },
      "source": [
        "## 3-layer Network + ReLU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xucFjeWLryd-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a76b7f3-04f7-4e31-e6c2-ff0806ee4064"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim=784, \n",
        "                 hidden_dim=(32,32), \n",
        "                 output_dim=10):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim[0])\n",
        "        self.fc2 = nn.Linear(hidden_dim[0], hidden_dim[1])\n",
        "        self.fc3 = nn.Linear(hidden_dim[1], output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = MLP()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "device = torch.device('cuda')\n",
        "model.to(device)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (fc1): Linear(in_features=784, out_features=32, bias=True)\n",
              "  (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
              "  (fc3): Linear(in_features=32, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQPzJum6t34S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f1ba96b-5529-4b51-97ab-f683cd99faf5"
      },
      "source": [
        "trainer = Trainer(trainloader = train_dataloader,\n",
        "                  testloader = test_dataloader,\n",
        "                  model = model,\n",
        "                  criterion = criterion,\n",
        "                  optimizer = optimizer,\n",
        "                  device = device)\n",
        "\n",
        "trainer.train(epoch = 10)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1  loss: 1.755\n",
            "epoch: 2  loss: 0.594\n",
            "epoch: 3  loss: 0.420\n",
            "epoch: 4  loss: 0.367\n",
            "epoch: 5  loss: 0.338\n",
            "epoch: 6  loss: 0.317\n",
            "epoch: 7  loss: 0.300\n",
            "epoch: 8  loss: 0.286\n",
            "epoch: 9  loss: 0.272\n",
            "epoch: 10  loss: 0.260\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfVnHhN9t4vC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6020e68-57e2-4eab-d299-091a9c53bb65"
      },
      "source": [
        "trainer.test()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_acc: 0.924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICv5Wc_TuH3B"
      },
      "source": [
        "#### Q2. Activation function 별로 Layer 수를 늘리는 것이 성능이 어떻게 변하나요? 양상이 다르게 나타난다면 왜 그럴까요?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "시그모이드는 레이어가 깊어질 수록 성능이 떨어진다. Q1에서 언급했듯이 시그모이드는 back할때때 0과 1사이 값이 계속 곱해져서 결국국 기울기값이 희미해지는 특징 때문인것 같다."
      ],
      "metadata": {
        "id": "FTYCnUSwhOjo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54oz80tfuH5M"
      },
      "source": [
        "\n",
        "#### Q3. Activation function이 존재하지 않는다면 어떤 일이 일어날까요?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "히든 레이어를 쌓는 의미가 없어집니다.f(x)=w*x 인 히든 레이어로 fff(x)를 구해볼때 w*w*w*x 가 되서 결국은 (w^3)*x 로 하나의 레이어를 추가한것과\n",
        "다를바가 없기 때문입니다."
      ],
      "metadata": {
        "id": "YabHzFPXiNSW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmrGO-uru01w"
      },
      "source": [
        "# 3. Optimization\n",
        "\n",
        "이번 section에서는 sgd, momentum, Adam등의 optimizer를 사용해보고 성능을 비교해보도록 하겠습니다.\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1xfCTx8xj4zoaombrK2bSN9nv0Z3r95jp)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jjuv9XW2Cij"
      },
      "source": [
        "- input: 784\n",
        "- hidden: (32, 32)\n",
        "- output: 10\n",
        "- activation: relu\n",
        "- **optimizer: sgd or momentum or adam**\n",
        "- loss: cross-entropy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxhHMDjHxRV4"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim=784, \n",
        "                 hidden_dim=(32,32), \n",
        "                 output_dim=10):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim[0])\n",
        "        self.fc2 = nn.Linear(hidden_dim[0], hidden_dim[1])\n",
        "        self.fc3 = nn.Linear(hidden_dim[1], output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlkMXZfKxpRg"
      },
      "source": [
        "## 3-layer Network + ReLU + SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCDbH1Bbxify",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98837c83-9df7-4468-ea3f-35f3ec91cc35"
      },
      "source": [
        "model = MLP()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "device = torch.device('cuda')\n",
        "model.to(device)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (fc1): Linear(in_features=784, out_features=32, bias=True)\n",
              "  (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
              "  (fc3): Linear(in_features=32, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lchz9vtUxkiD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "515dba7d-4fb8-4ec9-9584-5efbd7d30758"
      },
      "source": [
        "trainer = Trainer(trainloader = train_dataloader,\n",
        "                  testloader = test_dataloader,\n",
        "                  model = model,\n",
        "                  criterion = criterion,\n",
        "                  optimizer = optimizer,\n",
        "                  device = device)\n",
        "\n",
        "trainer.train(epoch = 10)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1  loss: 1.745\n",
            "epoch: 2  loss: 0.630\n",
            "epoch: 3  loss: 0.431\n",
            "epoch: 4  loss: 0.373\n",
            "epoch: 5  loss: 0.341\n",
            "epoch: 6  loss: 0.318\n",
            "epoch: 7  loss: 0.300\n",
            "epoch: 8  loss: 0.285\n",
            "epoch: 9  loss: 0.273\n",
            "epoch: 10  loss: 0.261\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ksQiJFqxls_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a8f51bd-4cb1-4f6c-cbe9-49146e140ebf"
      },
      "source": [
        "trainer.test()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_acc: 0.924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1nhBnqWxw4a"
      },
      "source": [
        "## 3-layer Network + ReLU + Momentum\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idG8_h_QxmQi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9646c89-5d5c-44bd-b494-2ed472caa73b"
      },
      "source": [
        "model = MLP()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.99)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "device = torch.device('cuda')\n",
        "model.to(device)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (fc1): Linear(in_features=784, out_features=32, bias=True)\n",
              "  (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
              "  (fc3): Linear(in_features=32, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDNAysVqxxOk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a553ec9e-5f63-48e2-e6b4-ab973fbac620"
      },
      "source": [
        "trainer = Trainer(trainloader = train_dataloader,\n",
        "                  testloader = test_dataloader,\n",
        "                  model = model,\n",
        "                  criterion = criterion,\n",
        "                  optimizer = optimizer,\n",
        "                  device = device)\n",
        "\n",
        "trainer.train(epoch = 10)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1  loss: 0.595\n",
            "epoch: 2  loss: 0.265\n",
            "epoch: 3  loss: 0.215\n",
            "epoch: 4  loss: 0.200\n",
            "epoch: 5  loss: 0.183\n",
            "epoch: 6  loss: 0.178\n",
            "epoch: 7  loss: 0.164\n",
            "epoch: 8  loss: 0.143\n",
            "epoch: 9  loss: 0.160\n",
            "epoch: 10  loss: 0.145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0U2s0hux_n6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91c12c75-4ffa-415c-8914-be367d47797f"
      },
      "source": [
        "trainer.test()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_acc: 0.948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZobOWhPxytT"
      },
      "source": [
        "## 3-layer Network + ReLU + Adam\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7xVOWgZxzoS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ccad87d-3223-4071-8486-afb412eb80ad"
      },
      "source": [
        "model = MLP()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "device = torch.device('cuda')\n",
        "model.to(device)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (fc1): Linear(in_features=784, out_features=32, bias=True)\n",
              "  (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
              "  (fc3): Linear(in_features=32, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R4pzcKPyFBi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f0666f5-08f8-45c2-962a-2beaa4893e50"
      },
      "source": [
        "trainer = Trainer(trainloader = train_dataloader,\n",
        "                  testloader = test_dataloader,\n",
        "                  model = model,\n",
        "                  criterion = criterion,\n",
        "                  optimizer = optimizer,\n",
        "                  device = device)\n",
        "\n",
        "trainer.train(epoch = 10)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1  loss: 0.291\n",
            "epoch: 2  loss: 0.171\n",
            "epoch: 3  loss: 0.146\n",
            "epoch: 4  loss: 0.135\n",
            "epoch: 5  loss: 0.124\n",
            "epoch: 6  loss: 0.119\n",
            "epoch: 7  loss: 0.112\n",
            "epoch: 8  loss: 0.108\n",
            "epoch: 9  loss: 0.106\n",
            "epoch: 10  loss: 0.107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgAEpCJ_yHAi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83873912-0359-463c-c131-e68b0a0451d0"
      },
      "source": [
        "trainer.test()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_acc: 0.957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCeNbNhIyyR6"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOLVGSb7yyWW"
      },
      "source": [
        "#### Q4. Optimizer 별로 수렴 속도가 어떻게 다른가요? \n",
        "##### Q4.1 수렴 속도가 다르다면 sgd와 momentum의 차이는 왜 발생할까요? \n",
        "##### Q4.2 수렴 속도가 다르다면 momentum과 Adam의 차이는 왜 발생할까요?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 모멘텀은 이전 변화량을 부분적으로 기억해서 다음 변화할때 이를 반영한다. loss가 비교적 큰 폭으로 줄었음을 알 수 있다. \n",
        "2. 아담의 경우 이전까지의 변화량들을 먼 변화량일 수록 적게 비율을 부과하는\n",
        "rmsprop의 방식과 모멘텀의 방식을 합친 방식이다. 모멘텀은 loss가 대체로는 작아지지만 말년에 커지기도 한다. adam을 사용하면 이를 좀 완화할 수 있다."
      ],
      "metadata": {
        "id": "lqFTy-oS8XJu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNP78kE2zbPQ"
      },
      "source": [
        "## 4. Regularization\n",
        "\n",
        "이번 section에서는 image data에서 주로 사용되는 batch-normalization을 어떻게 사용하는지를 확인해보겠습니다.\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1xZSWZiSxuGZAsonghidhTSfUEYiuxRtN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1YretVf2eRy"
      },
      "source": [
        "- input: 784\n",
        "- hidden: 32 or (32, 32)\n",
        "- output: 10\n",
        "- activation: relu\n",
        "- optimizer: adam\n",
        "- **regularizer: batch_norm**\n",
        "- loss: cross-entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qmvn2oNj0Spe"
      },
      "source": [
        "## 3-layer Network + ReLU + Adam + batch_norm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FBt1qcYzrph"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim=784, \n",
        "                 hidden_dim=(32,32), \n",
        "                 output_dim=10):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim[0])\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_dim[0])\n",
        "        self.fc2 = nn.Linear(hidden_dim[0], hidden_dim[1])\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_dim[1])\n",
        "        self.fc3 = nn.Linear(hidden_dim[1], output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VSAzG4uz_4i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "286395e7-9b4d-49e4-8a53-8cf44899f0d5"
      },
      "source": [
        "model = MLP()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "device = torch.device('cuda')\n",
        "model.to(device)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (fc1): Linear(in_features=784, out_features=32, bias=True)\n",
              "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
              "  (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc3): Linear(in_features=32, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDYfHC9x0BKy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a096a37-8c09-4a3e-e0ba-23d09613d83b"
      },
      "source": [
        "trainer = Trainer(trainloader = train_dataloader,\n",
        "                  testloader = test_dataloader,\n",
        "                  model = model,\n",
        "                  criterion = criterion,\n",
        "                  optimizer = optimizer,\n",
        "                  device = device)\n",
        "\n",
        "trainer.train(epoch = 10)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1  loss: 0.265\n",
            "epoch: 2  loss: 0.144\n",
            "epoch: 3  loss: 0.119\n",
            "epoch: 4  loss: 0.105\n",
            "epoch: 5  loss: 0.095\n",
            "epoch: 6  loss: 0.090\n",
            "epoch: 7  loss: 0.081\n",
            "epoch: 8  loss: 0.075\n",
            "epoch: 9  loss: 0.075\n",
            "epoch: 10  loss: 0.070\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdpSN6uu0CZy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e975d3d7-5c6c-4aa1-c7b3-b0bd57f52e8b"
      },
      "source": [
        "trainer.test()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_acc: 0.970\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qDotwtf3m-Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb2d0e79-baf7-4c2c-d80f-a78f22889fef"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "count_parameters(model)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26634"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WSYxs4F0Kbt"
      },
      "source": [
        "#### Q5. Batch-normalization을 사용하기 전 후로 성능이 어떻게 변화했나요? 왜 이러한 변화가 일어났을까요?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "배치놈을 사용하면 지그재그로 가지않고 비교적 정방향으로 loss가 빠르게 줄어든다.\n",
        "성능이 좋아졌습니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "oG8gXKVkWAH4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6xu4cQl0fOy"
      },
      "source": [
        "# 5. Fully-Connected Layer vs Convolution Layer\n",
        "\n",
        "지금까지 model의 다양한 node를 바꿔가며 mnist의 성능 변화를 확인해보는 실습을 진행해 보았습니다. \\\\\n",
        "비록, fully-connected network가 mnist 데이터에서 높은 성능을 내는데는 문제가 없었지만, 모든 layer를 fully-connected layer로 만드는 것은 엄청난 파라미터와 연산량을 필요로 하기 때문에 더욱 큰 고화질의 이미지 데이터를 처리하는데는 적합하지 않습니다. \\\\ \n",
        "\n",
        "따라서, 이번 section에서는 이미지 데이터 처리에 주로 사용되는 convolution layer를 사용해보고 파라미터 수와 성능이 어떻게 변화하는지 확인해보도록 하겠습니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBH4WROS2-H4"
      },
      "source": [
        "## Convolution Operation\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1xdjTf4ab0P8qfu_TaLJ4TZzt5sk3twS6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u86dyWA98qQ_"
      },
      "source": [
        "### Q6. Input이 (H, W, C) 일 때, stride S의 2개의 (F * F) convolutional filter를 적용하면 output이 어떻게 되나요?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "필터를 두개 사용했으므로 채널은 2가 될것입니니다.\n",
        "위 그림에서 5x5가 3x3을 만나 3x3 : (5-3) // 1 + 1가 되었는데\n",
        "일반화하면\n",
        "((H-F)//S +1 , (W-F)//S +1, 2) 가 됩니다."
      ],
      "metadata": {
        "id": "3aQTfYDjewVb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3Zxfe-DYcSCQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tfEDx7429cL"
      },
      "source": [
        "class Conv(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim=784, \n",
        "                 output_dim=10):\n",
        "        super(Conv, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1,\n",
        "                               out_channels=8,\n",
        "                               kernel_size=7,\n",
        "                               stride=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=8,\n",
        "                               out_channels=8,\n",
        "                               kernel_size=7,\n",
        "                               stride=2)\n",
        "        self.fc = nn.Linear(3*3*8, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # should reshape data into image\n",
        "        x = x.reshape(-1, 1, 28, 28)\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = x.reshape(-1, 3*3*8)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2QbRqEz-FzB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87f1eeb2-641f-4789-bed8-412b92872d68"
      },
      "source": [
        "model = Conv()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "device = torch.device('cuda')\n",
        "model.to(device)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv(\n",
              "  (conv1): Conv2d(1, 8, kernel_size=(7, 7), stride=(2, 2))\n",
              "  (conv2): Conv2d(8, 8, kernel_size=(7, 7), stride=(2, 2))\n",
              "  (fc): Linear(in_features=72, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTRB0_15-eYy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0af7049e-3d63-462c-cc69-14411b3487a5"
      },
      "source": [
        "trainer = Trainer(trainloader = train_dataloader,\n",
        "                  testloader = test_dataloader,\n",
        "                  model = model,\n",
        "                  criterion = criterion,\n",
        "                  optimizer = optimizer,\n",
        "                  device = device)\n",
        "\n",
        "trainer.train(epoch = 10)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1  loss: 0.203\n",
            "epoch: 2  loss: 0.089\n",
            "epoch: 3  loss: 0.079\n",
            "epoch: 4  loss: 0.077\n",
            "epoch: 5  loss: 0.077\n",
            "epoch: 6  loss: 0.076\n",
            "epoch: 7  loss: 0.075\n",
            "epoch: 8  loss: 0.075\n",
            "epoch: 9  loss: 0.073\n",
            "epoch: 10  loss: 0.070\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuFiCnDa-fpC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6af3f97c-69bb-453e-9b31-3b1bb69b26d8"
      },
      "source": [
        "trainer.test()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_acc: 0.969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRVwFbhU-8TZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "753e3e5b-cc07-4fc3-fbe1-ca936c060e7c"
      },
      "source": [
        "count_parameters(model)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4274"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ayzu25pm_KNH"
      },
      "source": [
        "##### Q7. covolution operation은 image데이터를 다루는데 있어서 fully-connected layer에 비해 어떤 점에서 효과적일까요?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "필터를 사용하면서 뭔가 엣지나 어떤 이미지 만의 경향성을\n",
        "유지하기 쉬워집니다. 풀링으로 더 효과적으로 유지됩니다."
      ],
      "metadata": {
        "id": "MnBasmLBcJdr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdCwjzXX_-jU"
      },
      "source": [
        "## 6. Do It By Yourself\n",
        "\n",
        "위에서 했던 실습들과 수업에 배웠던 다양한 network component들을 참조해서 20,000개 이하의 파라미터로 98%의 accuracy를 달성해보세요!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "알렉스넷을 흉내내보았습니다."
      ],
      "metadata": {
        "id": "KN7TiXorFONn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOqAaJkGAAuC"
      },
      "source": [
        "class CustomModel(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim=784, \n",
        "                 output_dim=10):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1,\n",
        "                               out_channels=8,\n",
        "                               kernel_size=5,\n",
        "                               stride=1)\n",
        "        \n",
        "\n",
        "        self.pool1 = nn.Conv2d(in_channels=8,out_channels=8,kernel_size=3,stride=2)\n",
        "        self.bn1 = nn.BatchNorm2d(8)\n",
        "\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=8,\n",
        "                               out_channels=8,\n",
        "                               kernel_size=5,\n",
        "                               stride=1)\n",
        "        \n",
        "        self.pool2 = nn.Conv2d(in_channels=8,out_channels=8,kernel_size=2,stride=1)\n",
        "        self.bn2 = nn.BatchNorm2d(8)\n",
        "\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(in_channels=8,\n",
        "                               out_channels=8,\n",
        "                               kernel_size=4,\n",
        "                               stride=1)\n",
        "\n",
        "        self.fc = nn.Linear(3*3*8, output_dim)\n",
        "    def forward(self, x):\n",
        "        # should reshape data into image\n",
        "        x = x.reshape(-1, 1, 28, 28)\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x=self.pool1(x)\n",
        "        x=self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "  \n",
        "        x=self.pool2(x)\n",
        "        x=self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = x.reshape(-1, 3*3*8)\n",
        "        x = self.fc(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B-6gww_Af0E"
      },
      "source": [
        "model = CustomModel()\n",
        "if count_parameters(model) > 20000:\n",
        "  raise AssertionError"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcA3XbRUAaUh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcadbefb-2fe3-47f4-b66a-47b58bf23c25"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "device = torch.device('cuda')\n",
        "model.to(device)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomModel(\n",
              "  (conv1): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool1): Conv2d(8, 8, kernel_size=(3, 3), stride=(2, 2))\n",
              "  (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): Conv2d(8, 8, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool2): Conv2d(8, 8, kernel_size=(2, 2), stride=(1, 1))\n",
              "  (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3): Conv2d(8, 8, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (fc): Linear(in_features=72, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJBKdQTyAd24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de9ff16e-9665-43cf-919f-de1b1277e40c"
      },
      "source": [
        "trainer = Trainer(trainloader = train_dataloader,\n",
        "                  testloader = test_dataloader,\n",
        "                  model = model,\n",
        "                  criterion = criterion,\n",
        "                  optimizer = optimizer,\n",
        "                  device = device)\n",
        "\n",
        "trainer.train(epoch = 10)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1  loss: 0.185\n",
            "epoch: 2  loss: 0.084\n",
            "epoch: 3  loss: 0.071\n",
            "epoch: 4  loss: 0.064\n",
            "epoch: 5  loss: 0.061\n",
            "epoch: 6  loss: 0.056\n",
            "epoch: 7  loss: 0.052\n",
            "epoch: 8  loss: 0.053\n",
            "epoch: 9  loss: 0.050\n",
            "epoch: 10  loss: 0.048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0URQgBu_AfJB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76277ab1-5bcd-4544-a589-d06be9f92794"
      },
      "source": [
        "trainer.test()"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_acc: 0.982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fp_V8lHJH2lR"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-86X-wJGn4Dk"
      },
      "execution_count": 45,
      "outputs": []
    }
  ]
}